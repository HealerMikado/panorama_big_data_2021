{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86cc806-aef1-43b8-8baf-999932192145",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Graded Lab : Exploring USA weather data\n",
    "\n",
    "In this lab you will explore weather data from National Oceanic and Atmospheric Administration (NOAA).\n",
    "\n",
    ">If your are curious, they are avalable here https://noaa-isd-pds.s3.amazonaws.com/index.html, or directly in FTP access here : ftp.ncdc.noaa.gov. You can find weather data from 1901 to today.\n",
    "\n",
    "Raw data are stored in ISD (Integrated Surface Data) format. It's a strange format, with a mandatory section with positional fields, and a additional section with variable fields. For this lab, the dataset has been transform into json. But no other processing had been done. For exemple, missing temperature are not filtered and are coded with 999.9. The lab's dataset contains more than 100 years of weather data. Its total size is about 4Go once compressed (and around 40Go uncrompressed).\n",
    "\n",
    "For instance, here is an exemple of a reccord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069ea201-d80e-4264-9a0d-b8c2e38e79fc",
   "metadata": {},
   "source": [
    "```js\n",
    "{\n",
    "   \"weather_station\":\"010040\",\n",
    "   \"latitude\":78.933,\n",
    "   \"longitude\":11.883,\n",
    "   \"elevation\":42,\n",
    "   \"time\":\"1975-03-04T18:00:00+00:00\",\n",
    "   \"air_temperature\":{\n",
    "      \"value\":-24.0,\n",
    "      \"quality\":\"1\"\n",
    "   },\n",
    "   \"dew_point\":{\n",
    "      \"value\":-27.0,\n",
    "      \"quality\":\"1\"\n",
    "   },\n",
    "   \"wind_speed\":{\n",
    "      \"value\":1.0,\n",
    "      \"quality\":\"1\"\n",
    "   },\n",
    "   \"wind_direction\":{\n",
    "      \"value\":\"160\",\n",
    "      \"quality\":\"1\"\n",
    "   },\n",
    "   \"sea_level_pressure\":{\n",
    "      \"value\":1002.1,\n",
    "      \"quality\":\"\"\n",
    "   },\n",
    "   \"sky_ceiling\":{\n",
    "      \"value\":22000,\n",
    "      \"quality\":\"1\"\n",
    "   },\n",
    "   \"visibility_distance\":{\n",
    "      \"value\":50000,\n",
    "      \"quality\":\"1\"\n",
    "   },\n",
    "   \"liquid_precip\":[\n",
    "      {\n",
    "         \"hours\":99,\n",
    "         \"depth\":0.0\n",
    "      }\n",
    "   ],\n",
    "  \"sky_cover_condition\":[\n",
    "      {\n",
    "         \"base_height\":50000,\n",
    "         \"cloud_type\":\"Cirrus and/or Cirrocumulus\",\n",
    "\t\t \"coverage\":8\n",
    "      }\n",
    "   ],\n",
    "   \"extreme_temperature\":[\n",
    "      {\n",
    "         \"hours\":999,\n",
    "         \"code\":\"M\",\n",
    "         \"temperature\":{\n",
    "            \"value\":-23.0,\n",
    "            \"quality\":\"1\"\n",
    "         }\n",
    "      }\n",
    "   ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f8668-37a7-46bd-887d-b0a074357c12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cluster setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd34238-d628-4100-9900-a7b314f6bcb4",
   "metadata": {},
   "source": [
    "Is spark running ? You can start the lab once you get a message like `SparkSession available as 'spark'.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c2cd00-b8a1-4259-822e-2f26d13a7506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T07:21:06.080969Z",
     "iopub.status.busy": "2022-04-14T07:21:06.080747Z",
     "iopub.status.idle": "2022-04-14T07:21:37.718045Z",
     "shell.execute_reply": "2022-04-14T07:21:37.717339Z",
     "shell.execute_reply.started": "2022-04-14T07:21:06.080943Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f684f3886f1a473097dc3f2450acd5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>0</td><td>application_1649920197808_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-95-233.ec2.internal:20888/proxy/application_1649920197808_0001/\" class=\"emr-proxy-link\" emr-resource=\"j-X55LDM6T8G2W\n",
       "\" application-id=\"application_1649920197808_0001\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-93-144.ec2.internal:8042/node/containerlogs/container_1649920197808_0001_01_000001/livy\" >Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7efef21d6750>"
     ]
    }
   ],
   "source": [
    "# Spark session\n",
    "spark\n",
    "\n",
    "# Configuraion\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3.useRequesterPaysHeader\",\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57843d29-880d-4e4b-922a-d03135cffb90",
   "metadata": {},
   "source": [
    "Usefull import for the lab. You can import more functions if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b36402-8ad6-462c-8bfc-aa36374550b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T11:43:16.774722Z",
     "iopub.status.busy": "2022-04-14T11:43:16.774513Z",
     "iopub.status.idle": "2022-04-14T11:43:17.616287Z",
     "shell.execute_reply": "2022-04-14T11:43:17.615594Z",
     "shell.execute_reply.started": "2022-04-14T11:43:16.774699Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3e2741ced84b028ed7269da6404b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import count, min, max, mean, exp, first, from_json, window, col, expr, year, month, explode, sum, row_number, avg, abs\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, ArrayType, TimestampType, BooleanType, LongType, DoubleType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65b2ff2-e895-4f72-96e6-3d41789e9d0c",
   "metadata": {},
   "source": [
    "Data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39e2db0e-3659-4b77-8d71-2c7afe3d9df6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T12:05:13.562146Z",
     "iopub.status.busy": "2022-04-14T12:05:13.561926Z",
     "iopub.status.idle": "2022-04-14T12:05:13.629126Z",
     "shell.execute_reply": "2022-04-14T12:05:13.628591Z",
     "shell.execute_reply.started": "2022-04-14T12:05:13.562122Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d0f98e4e44475c8274b2c196961819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"air_temperature\",StructType([\n",
    "        StructField(\"quality\",StringType(),True)\n",
    "        ,StructField(\"value\",DoubleType(),True)]),True)\n",
    "    ,StructField(\"dew_point\",StructType([\n",
    "        StructField(\"quality\",StringType(),True)\n",
    "        ,StructField(\"value\",DoubleType(),True)]),True)\n",
    "    ,StructField(\"wind_speed\",StructType([\n",
    "        StructField(\"quality\",StringType(),True)\n",
    "        ,StructField(\"value\",DoubleType(),True)]),True)\n",
    "    ,StructField(\"elevation\",LongType(),True)\n",
    "    ,StructField(\"extreme_temperature\",ArrayType(StructType([\n",
    "        StructField(\"code\",StringType(),True)\n",
    "        ,StructField(\"hours\",LongType(),True)\n",
    "        ,StructField(\"temperature\",StructType([\n",
    "            StructField(\"quality\",StringType(),True)\n",
    "            ,StructField(\"value\",DoubleType(),True)]),True)]),True),True)\n",
    "    ,StructField(\"latitude\",DoubleType(),True)\n",
    "    ,StructField(\"liquid_precip\",ArrayType(StructType([\n",
    "        StructField(\"depth\",StringType(),True)\n",
    "        ,StructField(\"hours\",LongType(),True)]),True),True)\n",
    "    ,StructField(\"longitude\",DoubleType(),True)\n",
    "    ,StructField(\"sea_level_pressure\",StructType([\n",
    "        StructField(\"quality\",StringType(),True),\n",
    "        StructField(\"value\",DoubleType(),True)]),True)\n",
    "    ,StructField(\"sky_ceiling\",StructType([\n",
    "        StructField(\"quality\",StringType(),True)\n",
    "        ,StructField(\"value\",LongType(),True)]),True)\n",
    "    ,StructField(\"sky_cover_condition\",ArrayType(StructType([\n",
    "        StructField(\"base_height\",LongType(),True)\n",
    "        ,StructField(\"cloud_type\",StringType(),True)\n",
    "        ,StructField(\"coverage\",LongType(),True)]),True),True)\n",
    "    ,StructField(\"time\",TimestampType(),True)\n",
    "    ,StructField(\"visibility_distance\",StructType([\n",
    "        StructField(\"quality\",StringType(),True)\n",
    "        ,StructField(\"value\",LongType(),True)]),True)\n",
    "    ,StructField(\"weather_station\",StringType(),True)\n",
    "    ,StructField(\"wind_direction\",StructType([\n",
    "        StructField(\"quality\",StringType(),True),\n",
    "        StructField(\"value\",StringType(),True)]),True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb074211-695d-497f-9335-e96626e778d6",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8678893a-4aef-4d2e-a644-d9349ae388de",
   "metadata": {},
   "source": [
    "1. Import the dataset from `s3://spark-lab-input-data-ensai20212022/weather_data/` with the provided schema under the name `meteo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3993bb88-ddfe-4deb-ad7b-0ecfe694ce9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T12:05:16.479832Z",
     "iopub.status.busy": "2022-04-14T12:05:16.479609Z",
     "iopub.status.idle": "2022-04-14T12:05:16.760741Z",
     "shell.execute_reply": "2022-04-14T12:05:16.760030Z",
     "shell.execute_reply.started": "2022-04-14T12:05:16.479809Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0f3ac92610499e9905612cab801c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "824ad462-31e2-4efb-a63c-8f8ccc41021c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T13:36:09.210494Z",
     "iopub.status.busy": "2022-04-08T13:36:09.210246Z",
     "iopub.status.idle": "2022-04-08T13:36:09.279307Z",
     "shell.execute_reply": "2022-04-08T13:36:09.278694Z",
     "shell.execute_reply.started": "2022-04-08T13:36:09.210468Z"
    },
    "tags": []
   },
   "source": [
    "2. Print the dataframe schema.What type of variable are `elevation` and `time` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be386767-bf56-43e2-b573-e56d4c8a6579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T07:41:15.110081Z",
     "iopub.status.busy": "2022-04-14T07:41:15.109860Z",
     "iopub.status.idle": "2022-04-14T07:41:15.165510Z",
     "shell.execute_reply": "2022-04-14T07:41:15.164928Z",
     "shell.execute_reply.started": "2022-04-14T07:41:15.110056Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cdd4e0-7ea6-4c9a-b304-6cbf43bdf004",
   "metadata": {},
   "source": [
    "3. Print the first 9 rows. You can use `vertical=True` to get a prettier result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18039be-74f8-4228-af8a-0f30ce924557",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T12:05:19.098053Z",
     "iopub.status.busy": "2022-04-14T12:05:19.097831Z",
     "iopub.status.idle": "2022-04-14T12:05:26.430778Z",
     "shell.execute_reply": "2022-04-14T12:05:26.430071Z",
     "shell.execute_reply.started": "2022-04-14T12:05:19.098030Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71303959",
   "metadata": {},
   "source": [
    "4. Count how many different stations there are with the `countDistinct()` method. What is the interest of `approx_count_distinct()`? (You will demonstrate this interest by timing three instructions: one for `countDistinct()` and two for `approx_count_distinct()` with different values of `rsd`. See the [documentation](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.functions.approx_count_distinct.html) for more information.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e11863f-e4aa-48ec-98f4-8b8631f2338e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T07:27:27.102119Z",
     "iopub.status.busy": "2022-04-14T07:27:27.101893Z",
     "iopub.status.idle": "2022-04-14T07:29:08.736745Z",
     "shell.execute_reply": "2022-04-14T07:29:08.735982Z",
     "shell.execute_reply.started": "2022-04-14T07:27:27.102094Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b8dd390-f0c1-4d6a-9ed6-90a8136166b1",
   "metadata": {},
   "source": [
    "5. The dataset is way too big to work on it as is (it would take minutes to run each instruction). Create a new dataset called `meteo_small` containing a sample at a rate of a 500th.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01a0183-274f-4fd4-bcb1-a33989ad6992",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T12:05:30.949421Z",
     "iopub.status.busy": "2022-04-14T12:05:30.949122Z",
     "iopub.status.idle": "2022-04-14T12:07:36.709669Z",
     "shell.execute_reply": "2022-04-14T12:07:36.708953Z",
     "shell.execute_reply.started": "2022-04-14T12:05:30.949389Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f7a7b13-ab42-48ef-8cab-a49fa46c4cfd",
   "metadata": {},
   "source": [
    "6. Print the station at the highest altitude (`elevation`). The one at the lowest.\n",
    "Cautious : an elevation equals to 9999 means \"missing value\". Do not count a 9999 has a real elevation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124357fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e9b4b21",
   "metadata": {},
   "source": [
    "7. Count how many stations have an altitude lower then 500m. Do the same with the stations higher than 1000m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d7206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eabff9b2-6ad3-4347-b3f5-99c478d957c5",
   "metadata": {},
   "source": [
    "8. Filter missing and bad-quality air temperatures out of `meteo_small`.  You will make sure Spark actually performs the computation and stores the dataset `meteo_small` permanently. (Indeed, we will use `meteo_small`  again and again in the rest of the tutorial.) How many observations are deleted ?\n",
    "\n",
    "- Missing temperature are given the number `999.9`\n",
    "- We consider that good quality is encoded by 0, 1, 4, 5 or 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7cc0d3-8164-4b7b-88bc-c747aa6d7740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T12:07:36.710806Z",
     "iopub.status.busy": "2022-04-14T12:07:36.710639Z",
     "iopub.status.idle": "2022-04-14T12:07:38.015329Z",
     "shell.execute_reply": "2022-04-14T12:07:38.014642Z",
     "shell.execute_reply.started": "2022-04-14T12:07:36.710785Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4faa6273-b81a-4b2c-b1d5-a8fbc7834639",
   "metadata": {},
   "source": [
    "9. On `meteo_small`, compute the **number of records** and the **average temperature** by year. Order you results by temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6d67cb-6595-49d7-ba87-301a4563a970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T13:48:46.902624Z",
     "iopub.status.busy": "2022-04-08T13:48:46.902387Z",
     "iopub.status.idle": "2022-04-08T13:48:48.183190Z",
     "shell.execute_reply": "2022-04-08T13:48:48.182377Z",
     "shell.execute_reply.started": "2022-04-08T13:48:46.902596Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "994f1aab",
   "metadata": {},
   "source": [
    "10. Compute the min, mean, max temperature, and count for each possible combinations of year and station. Your output should be like this :\n",
    "\n",
    "| weather_station | year | temp_min | temp_max | temp_mean | records_count |\n",
    "| --------------- | ---- | -------- | -------- | ---------- | -------------- |\n",
    "| 036830          | 1992 | a        | b        | c          | d              |\n",
    "| 033730          | null | e        | f        | g          | h              |\n",
    "| 010010          | 1992 | i        | j        | k          | l              |\n",
    "| null            | 1992 | m        | n        | o          | p              |\n",
    "| 061000          | 1991 | q        | r        | s          | t              |\n",
    "\n",
    "A `null` value means this dimension isn't use for this row. For instance the row 2 gives the min, max, mean and record count for the station 033730, and the row 4 gives the min, max, mean and record count for the year 1992.\n",
    "Some points will be given if you can do the all the combinations of year and station without the null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62caa3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a082e03-3b3f-4769-9f63-6b3161f676bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T13:39:18.945984Z",
     "iopub.status.busy": "2022-04-08T13:39:18.945739Z",
     "iopub.status.idle": "2022-04-08T13:39:19.211230Z",
     "shell.execute_reply": "2022-04-08T13:39:19.210556Z",
     "shell.execute_reply.started": "2022-04-08T13:39:18.945956Z"
    },
    "tags": []
   },
   "source": [
    "11.   Add a column to `meteo_small` called `approximate_partial_humidity` computed with this formula\n",
    "$$RH_{approx} = 100 - 5 (T_{air} -T_{DP}) $$\n",
    "\n",
    "With $T_{DP}$ the dew point temperature and $T_{air}$ the air temperature.\n",
    "Cautious : some dew point temperature can be missing or of bad quality. The rules to filter those value are the same as air_temperature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d31f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70b045b6-cf5a-4360-9674-efaf2d39f63e",
   "metadata": {},
   "source": [
    "12. `sky_cover_condition` is of type array. How would you do to obtain a copy of the line for each item in the array? On `meteo_small` compute how many time each `cloud_type` appears. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d584a0-bc21-4c50-9c0b-8c70611ab84b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T10:08:04.708446Z",
     "iopub.status.busy": "2022-04-14T10:08:04.708190Z",
     "iopub.status.idle": "2022-04-14T10:08:06.993375Z",
     "shell.execute_reply": "2022-04-14T10:08:06.992668Z",
     "shell.execute_reply.started": "2022-04-14T10:08:04.708418Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1be72ef7",
   "metadata": {},
   "source": [
    "13. On `meteo_small`, compute the maximum, minimum, first and third quartile of recorded **wind speed** in year 1992 with `summary()`. If year 1992 is empty on your sample, please chose an other date. Again, to get the year from the `time` variable, you can use `year(\"time\")`. Is the computation exact? Why is it interesting to use `summary()` instead of running one different instructions for each statistic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2629f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8b77df9",
   "metadata": {},
   "source": [
    "14. Briefly explain why computing a maximum is well-suited to the \"reduce\" step of map-and-reduce algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1884207a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d01b8539-5c0a-4b2b-8a8a-17aba72dfc17",
   "metadata": {},
   "source": [
    "15. For this question, you will do a linear regression on `meteo_small` giving the **air temperature** as function of **year**, **elevation**, **longitude**, **dew_point** and **sky_ceiling**.\n",
    "\n",
    "    - Filter to keep only the good value of temperature and pressure (9999.9 = missing pressure)\n",
    "    - Create `VectorAssembler` and `LinearRegression` objects\n",
    "    - Apply these objects to our data\n",
    "    - Explore the results (coefficients, p-values)\n",
    "\n",
    "    Is **year** a good predictor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f559663a-69c7-495a-8fb9-87b276c35d91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T12:12:15.976851Z",
     "iopub.status.busy": "2022-04-14T12:12:15.976630Z",
     "iopub.status.idle": "2022-04-14T12:12:16.261547Z",
     "shell.execute_reply": "2022-04-14T12:12:16.260759Z",
     "shell.execute_reply.started": "2022-04-14T12:12:15.976825Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea023931",
   "metadata": {},
   "source": [
    "16. What is the difference between the `fit()` and `transform()` methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551263d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19b31e41",
   "metadata": {},
   "source": [
    "17. Repeat the regression for a few different years. You will use a `Pipeline` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607952a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00ad57a6-5cea-4d84-896b-b759d03ad3b0",
   "metadata": {},
   "source": [
    "18. Does the regression fall in the category of \"embarassingly parallel problems\"? (Explain) Is it an \"inherently sequential problem\" ? (Explain) Make sure you give examples of each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b27e3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
