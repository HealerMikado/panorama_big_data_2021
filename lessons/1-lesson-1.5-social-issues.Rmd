---
title: | 
    | Introduction to Big Data
    | Lesson 1.5 Social-issues
author: "Arthur Katossky & Rémi Pépin"
output: 
  xaringan::moon_reader:
    nature:
      highlightLines: 
      ratio: 16:10
      scroll: false
      countIncrementalSlides: false
    css: ["css/xaringan-themer.css", "css/mine.css"]
    self_contained: true
---

## Ethical issues

- **Privacy** : more data are collected and analyzed, but in what extend and for what ? 
- **Discrimination** : predictive justice, recruitment
- **Consent** : do individuals agree to give their data ? Do they really understand ? Have the choice ?
- **Transparency** : how models work ? What are their purpose ? 
- **Security** : more data collected = more risk of data breaches = more cyber attacks
- **Captology** : using data to influence people or keeping then engage (*doomscrolling*) 

Engaging all of these aspects is hard and clearly a team job. One may want to use reference guidelines. Take a look at [the Deon project](https://github.com/drivendataorg/deon) for an instance.

???

- too much information -> everyone is identifiable
- retroactive content (the collection of data depends on what the algorithm produces and the algorithm learns from the data, ex: video recommendations on YouTube)
- security issues (all the 3 giants are forced to comply by the American intelligence agencies)

---
## Are ML model discriminating ?

- [Twitter investigates racial bias in image previews](https://www.bbc.com/news/technology-54234822)
- [Amazon’s sexist AI recruiting tool: how did it go so wrong?](https://becominghuman.ai/amazons-sexist-ai-recruiting-tool-how-did-it-go-so-wrong-e3d14816d98e)
- [Predictive policing algorithms are racist. They need to be dismantled.](https://www.technologyreview.com/2020/07/17/1005396/predictive-policing-algorithms-racist-dismantled-machine-learning-bias-criminal-justice/)
- [Google Photos Tags Two African-Americans As Gorillas Through Facial Recognition Software](https://www.forbes.com/sites/mzhang/2015/07/01/google-photos-tags-two-african-americans-as-gorillas-through-facial-recognition-software/)


---
## Do data scientists do it on purpose ?
--

NO ! (most of the time)
--

- ML model learn from input data
- Most data collection is biased towards well-off young males of European ancestry
- Social prejudices are embedded into data and retrieved by algorithms

--

Possible solutions :
1. have a team with multiple profiles with multiple points of view
2. always allow user feedbacks and do not dismiss criticism
3. plan ahead about the potential harms of you data-based solution

---

## Environmental issues

- **Energy consumption**<br>The Internet : 10% electricity consumption worldwide<br>1 data center = consumption of 30 000 habs ¹
- **Matter matters**<br>Computers use metals (including rare earths), usually mined in developing countries wit low regulation and releasing tremendous amounts of pollutants 
- **Carbon Emissions / Water consumption**<br>Building and running data centres is polluting.<br><small>Data centre operator try to build green data centre by producing their own energy. Data centers can be couples with district heating (ex: Microsoft in Finland).</small>

.footnote[
¹ <small>[Source](https://www.fournisseur-energie.com/internet-plus-gros-pollueur-de-planete/)</small>
]

--

Big infrastructures are not always the most environmentally-friendly solution. Active work currently for measuring and mitigating environmental impacts of computing.

???

- environmental resource consumption of storing / computing / communication
- both the energ consumption
- but also what to do with all the waste
-  Cloud computing makes it easy to get state of the art infrastructures. Current python libraries make machine learning accessible. It's easier than ever to train and deploy consumming application so lot of companies does that.


Even if efforts are made to reduce all those issues, because it's easy to use the overall energy consumption of big data increase. Rebound effect

---

## Political issues

- **Surveillance** : Easy to watch people in the current era. Like targeted add, or detecting odd behaviour with pattern detection.
- **War** : A lot of the AI research is directed towards autonomous weapons.
- **Misinformation** : Target contents to polarize people (electoral manipulation), distilled propaganda (Chinese video on TikTok). Not new phenomenon, big data helps to industrialize it.
- **Transparency** : Algorithmic decisions that impact people's life (grants, asylum, access to essential services, etc.) deserve to be explicit and transparent ; however this exposes the decision to adversarial selection
- **Sovereignty** : currently Europe is dependent of American companies. OVH growing but sill behind. We are financing US company by using their services.

---

## Conclusion

It's a complex problem for ours democraties. Big data is here and will stay. Peoples need to be educated to understand the current state of the world.

???

- what independance do you get when all the data is in the hand of a handful of American companies? see the struggle of OVH for existing on this market
ML algorithms seem magical by lot of people. It's important to explain how they work and IA models are not intelligent (like chatGPT3)
